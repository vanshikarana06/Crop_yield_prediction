{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a91895b-57b1-4e87-ab66-ab0cb012b895",
   "metadata": {},
   "source": [
    "# Predicting Crop Yields in Indian States for Sustainable Agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cbbf0-951a-45d4-8745-24b430312f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab892c56-49e0-4f1e-9acf-f5e0b0f1a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"artifacts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f95976-6772-4cac-ad51-3d26f4035684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"crop_yield.csv\")\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a2af3-17a9-4673-8c8a-9e3f8edd7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d24fe5-b6f2-4e50-ac24-7123229a9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ac625-1b2d-4ebd-b851-b960df95dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f2140-96a4-4577-b411-063b72684368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa54de-9800-4f13-b931-3942942542c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of duplicate rows\n",
    "duplicates = df_raw.duplicated()\n",
    "print(duplicates.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489a887-64fd-4d02-8e30-a39c96569a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "num_cols = [\"Area\", \"Production\", \"Annual_Rainfall\", \"Fertilizer\", \"Pesticide\", \"Yield\"]\n",
    "df_raw[num_cols].hist(bins=30, figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5dad89-cc86-4caf-adff-295c83904d1d",
   "metadata": {},
   "source": [
    "## conclusion of above graphs :\n",
    "->Area col : Most farms in the dataset have small land area (maybe a few hectares). A few records have very large farm areas → these are outliers that dominate the axis scale.\n",
    "\n",
    "-> Same with other column (production , fertilizer , pesticides, yield)\n",
    "\n",
    "->Annual_Rainfall col : the shape looks roughly normal, centered around ~1200–1400. the right tail extends up beyond 4000–6000 → meaning there are some years/locations with unusually high rainfall (outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf9144-af19-488d-9d90-64afc612db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count plots for categorical features\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(data=df, x=\"Season\")\n",
    "plt.title(\"Season Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(data=df, x=\"Crop\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Crop Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc57cfd-af42-4ecb-955a-20630c93377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55677f9b-867f-4334-9654-0d8b143f0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming ONLY numeric features (cap + log1p)\n",
    "num_caplog_cols = [\"Area\", \"Annual_Rainfall\", \"Fertilizer\", \"Pesticide\"]\n",
    "\n",
    "# keeping Crop_Year as numeric (no label encoding, no log) because it's a time-based feature\n",
    "maybe_num_cols = [\"Crop_Year\"]\n",
    "\n",
    "# categorical columns present in your file\n",
    "candidate_cats = [\"Season\", \"Crop\", \"State\"]\n",
    "cat_cols = [c for c in candidate_cats if c in df_raw.columns]\n",
    "\n",
    "target_col = \"Yield\"\n",
    "drop_leakage = [\"Production\"]  # remove from features as including productio will overfit our model as yield=production/Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b6591-4ff9-4535-9e2f-839dc0aa43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building categorical levels (so we can encode consistently in Streamlit)\n",
    "cat_levels = {col: sorted(df_raw[col].dropna().astype(str).unique().tolist()) for col in cat_cols}\n",
    "\n",
    "def encode_categories(df, levels_dict):\n",
    "    df_enc = df.copy()\n",
    "    for col, levels in levels_dict.items():\n",
    "        lut = {v: i for i, v in enumerate(levels)}\n",
    "        df_enc[col] = df_enc[col].astype(str).map(lut)\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe8b0d-6266-4965-9dbd-9b300ee5de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply capping + log to selected numeric features (NOT the target)\n",
    "df_proc = df_raw.copy()\n",
    "caps = {}\n",
    "\n",
    "for col in num_caplog_cols:\n",
    "    lower = df_proc[col].quantile(0.01)\n",
    "    upper = df_proc[col].quantile(0.99)\n",
    "    caps[col] = {\"lower\": float(lower), \"upper\": float(upper)}\n",
    "    df_proc[col] = df_proc[col].clip(lower, upper)\n",
    "    df_proc[col] = np.log1p(df_proc[col])  # log(1+x) only for features\n",
    "\n",
    "# Encode categoricals\n",
    "df_proc = encode_categories(df_proc, cat_levels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affe6eb-3931-45bd-867c-1c5e0765d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build X and y (y is log1p of RAW Yield; we did NOT cap/log it above)\n",
    "y = np.log1p(df_raw[target_col].values)\n",
    "X = df_proc.drop(columns=[c for c in [target_col] + drop_leakage if c in df_proc.columns])\n",
    "\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "X.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1ef8e-ad9c-41e1-ae09-5d5b7dd614a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Area\", \"Annual_Rainfall\", \"Fertilizer\", \"Pesticide\"]\n",
    "df_proc[num_cols].hist(bins=30, figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478da46b-d232-4ccc-a65d-baa6413f22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearchCV (tuning Random Forest)\n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 300, 400, 500],\n",
    "    \"max_depth\": [None, 15, 20, 25, 30, 40],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,          # make 10 for quick test; raise to 30–50 if you have time\n",
    "    cv=kf,\n",
    "    scoring=\"r2\",\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "rs.fit(X, y)\n",
    "print(\"Best Params:\", rs.best_params_)\n",
    "print(\"Best CV R²:\", rs.best_score_)\n",
    "best_model = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560c9d6-98fc-4692-a68e-3bc588b7e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check CV with the tuned model\n",
    "cv_r2 = cross_val_score(best_model, X, y, cv=kf, scoring=\"r2\")\n",
    "cv_rmse = np.sqrt(-cross_val_score(best_model, X, y, cv=kf, scoring=\"neg_mean_squared_error\"))\n",
    "print(\"CV R²:\", cv_r2, \"Mean:\", cv_r2.mean())\n",
    "print(\"CV RMSE:\", cv_rmse, \"Mean:\", cv_rmse.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c95d6-3741-457f-88f2-23a69b47c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model + preprocessing artifacts (for Streamlit)\n",
    "joblib.dump(best_model, \"models/best_model_rf.joblib\")\n",
    "\n",
    "artifacts = {\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"cat_levels\": cat_levels,                  # for mapping text -> index\n",
    "    \"num_caplog_cols\": num_caplog_cols,        # features capped+logged\n",
    "    \"maybe_num_cols\": maybe_num_cols,          # kept raw\n",
    "    \"caps\": caps,                              # per-column lower/upper\n",
    "    \"feature_order\": X.columns.tolist(),       # exact order expected by model\n",
    "    \"drop_leakage\": drop_leakage,              # ['Production']\n",
    "    \"target\": {\"name\": target_col, \"log1p\": True}\n",
    "}\n",
    "with open(\"artifacts/preprocessing.json\", \"w\") as f:\n",
    "    json.dump(artifacts, f, indent=2)\n",
    "\n",
    "print(\"Saved -> models/best_model_rf.joblib  &  artifacts/preprocessing.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e5c0b-750b-4096-9182-cb8edcc29852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Helper to invert predictions to original Yield (useful to report metrics)\n",
    "def predict_yield_original(model, X_matrix):\n",
    "    y_log = model.predict(X_matrix)\n",
    "    return np.expm1(y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f309d-0e42-4a16-8586-f5e30ae133a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example overall check\n",
    "y_pred_orig = predict_yield_original(best_model, X)\n",
    "rmse_orig = np.sqrt(mean_squared_error(df_raw[target_col].values, y_pred_orig))\n",
    "r2_orig = r2_score(df_raw[target_col].values, y_pred_orig)\n",
    "print(f\"Original-scale RMSE: {rmse_orig:.4f} | R²: {r2_orig:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
